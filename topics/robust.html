<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="shortcut icon" href="../bootstrap/H.jpg">
	 
    <title>Robust</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
  </head>
  <body">
    <div class="page-header pt-3"></div>
    <hr>

    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <div class="container">
          <a class="navbar-brand" href="#">Navbar</a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ml-auto">
              <li class="nav-item">
                <a class="nav-link" href="./llms.html">&nbsp; LLM &nbsp; </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="./robust.html">&nbsp; Robust &nbsp; </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="./grl.html">&nbsp; GRL &nbsp; </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="./apx.html">&nbsp; APX &nbsp; </a>
              </li>
            </ul>
          </div>
      </div>
    </nav>
    <hr>

    <section id="abstract" class="container my-5">
        <h3>Robust and Explainable Machine Learning</h3>
        <p>AAAI (1), IJCAI (2), WSDM (1)</p>
    </section>

    <div class="container my-5">
        <div class="row">
          <!-- Card for Paper 1 -->
          <div class="col-lg-6 col-md-6 mb-4">
            <div class="card h-100">
              <img src="robust/AAAI-2024.png" class="card-img-top" alt="The overall framework of CIG">
              <div class="card-body">
                <h6 class="card-title">[AAAI-2024] Robust Image Ordinal Regression with Controllable Image Generation</h6>
                <p class="card-text" style="font-size: 14px;">Until recently, the question of the effective inductive 
                  bias of deep models on tabular data has remained unanswered. This paper investigates the hypothesis 
                  that arithmetic feature interaction is necessary for deep tabular learning. To test this point, we 
                  create a synthetic tabular dataset with a mild feature interaction assumption and examine a modified 
                  transformer architecture enabling arithmetical feature interactions, referred to as AMFormer. Results 
                  show that AMFormer outperforms strong counterparts in fine-grained tabular data modeling, data 
                  efficiency in training, and generalization. This is attributed to its parallel additive and 
                  multiplicative attention operators and prompt-based optimization, which facilitate the separation of 
                  tabular samples in an extended space with arithmetically-engineered features. Our extensive experiments 
                  on real-world data also validate the consistent effectiveness, efficiency, and rationale of AMFormer, 
                  suggesting it has established a strong inductive bias for deep learning on tabular data.</p>
              </div>
              <div class="card-footer">
                <a target="_blank" href="https://arxiv.org/abs/2402.02334" class="btn btn-primary">Read More</a>
              </div>
            </div>
          </div>

          <div class="col-lg-6 col-md-6 mb-4">
            <div class="card h-100">
              <img src="robust/IJCAI-2023.png" class="card-img-top" alt="The overall framework of CIG">
              <div class="card-body">
                <h6 class="card-title">[IJCAI-2023] Robust Image Ordinal Regression with Controllable Image Generation</h6>
                <p class="card-text" style="font-size: 14px;">Image ordinal regression has been mainly studied along the line of exploiting the order of categories. 
                  However, the issues of class imbalance and category overlap that are very common in ordinal regression were largely overlooked. 
                  As a result, the performance on minority categories is often unsatisfactory. 
                  In this paper, we propose a novel framework called CIG based on controllable image generation to directly tackle these two issues. 
                  Our main idea is to generate extra training samples with specific labels near category boundaries, 
                  and the sample generation is biased toward the less-represented categories. 
                  To achieve controllable image generation, we seek to separate structural and categorical information of images 
                  based on structural similarity, categorical similarity, and reconstruction constraints. We evaluate the effectiveness 
                  of our new CIG approach in three different image ordinal regression scenarios. 
                  The results demonstrate that CIG can be flexibly integrated with off-the-shelf image encoders or ordinal regression models to achieve improvement, 
                  and further, the improvement is more significant for minority categories.</p>
              </div>
              <div class="card-footer">
                <a target="_blank" href="https://arxiv.org/abs/2305.04213" class="btn btn-primary">Read More</a>
              </div>
            </div>
          </div>
          
          <div class="col-lg-6 col-md-6 mb-4">
            <div class="card h-100">
              <img src="robust/WSDM-2023.png" class="card-img-top" alt="The overall framework of RTGNN">
              <div class="card-body">
                <h6 class="card-title">[WSDM-2023] Robust Training of Graph Neural Networks via Noise Governance</h6>
                <p class="card-text"  style="font-size: 14px;">Graph Neural Networks (GNNs) have become widely-used models for semi-supervised learning. 
                  However, the robustness of GNNs in the presence of label noise remains a largely under-explored problem. 
                  In this paper, we consider an important yet challenging scenario where labels on nodes of graphs are not only noisy but also scarce. 
                  In this scenario, the performance of GNNs is prone to degrade due to label noise propagation and insufficient learning.
                  To address these issues, we propose a novel RTGNN (Robust Training of Graph Neural Networks via Noise Governance) framework 
                  that achieves better robustness by learning to explicitly govern label noise. 
                  More specifically, we introduce self-reinforcement and consistency regularization as supplemental supervision. 
                  The self-reinforcement supervision is inspired by the memorization effects of deep neural networks and aims to correct noisy labels. 
                  Further, the consistency regularization prevents GNNs from overfitting to noisy labels via mimicry loss in both the inter-view and intra-view perspectives. 
                  To leverage such supervisions, we divide labels into clean and noisy types, rectify inaccurate labels, and further generate pseudo-labels on unlabeled nodes. 
                  Supervision for nodes with different types of labels is then chosen adaptively. 
                  This enables sufficient learning from clean labels while limiting the impact of noisy ones. 
                  We conduct extensive experiments to evaluate the effectiveness of our RTGNN framework,
                   and the results validate its consistent superior performance over state-of-the-art methods with two types of label noises and various noise rates.</p>
              </div>
              <div class="card-footer">
                <a target="_blank" href="https://arxiv.org/abs/2211.06614" class="btn btn-primary">Read More</a>
              </div>
            </div>
          </div>
          
          <div class="col-lg-6 col-md-6 mb-4">
            <div class="card h-100">
              <img src="robust/IJCAI-2020.png" class="card-img-top" alt="User decision profiling example">
              <div class="card-body">
                <h6 class="card-title">[IJCAI-2020] Why We Go Where We Go: Profiling User Decisions on Choosing POIs</h6>
                <p class="card-text"  style="font-size: 14px;">While Point-of-Interest (POI) recommendation has been a popular topic of study for some time, 
                  little progress has been made for understanding why and how people make their decisions for the selection of POIs. 
                  To this end, in this paper, we propose a user decision profiling framework, named PROUD, 
                  which can identify the key factors in people's decisions on choosing POIs. 
                  Specifically, we treat each user decision as a set of factors and provide a method for learning factor embeddings. 
                  A unique perspective of our approach is to identify key factors, while preserving decision structures seamlessly, 
                  via a novel scalar projection maximization objective. 
                  Exactly solving the objective is non-trivial due to a sparsity constraint. 
                  To address this, our PROUD adopts a self projection attention and an L2 regularized sparse activation to 
                  directly estimate the likelihood of each factor to be a key factor. 
                  Finally, extensive experiments on real-world data validate the advantage of PROUD in preserving user decision structures. 
                  Also, our case study indicates that the identified key decision factors can help us to provide more interpretable recommendations and analyses.</p>
              </div>
              <div class="card-footer">
                <a target="_blank" href="https://www.ijcai.org/Proceedings/2020/478" class="btn btn-primary">Read More</a>
              </div>
            </div>
          </div>

        </div>
    </div>      

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>
  </body>
</html>